[toc]

# 论文草稿

-----

标题： 基于图神经网络的跨域自适应多目标跟踪算法研究与应用

1. 绪论
   1. 研究背景与意义
   2. 国内外研究现状：1.2.1 基于深度学习的多目标跟踪算法概述 1.2.2 图神经网络在多目标跟踪中的应用 1.2.3 跨域视觉感知与自适应方法研究
   3. 本文主要创新点与贡献
   4. 论文结构安排
2. 基础理论
   1. 图神经网络理论基础
   2. 跨域视觉感知与自适应建模基础
   3. 数据集与评价方法
   4. 本章小结
3. 基于图神经网络的多目标跟踪算法研究
   1. 问题建模与评价方法
   2. 基于双图协同关联建模的跟踪框架： 3.2.1 轨迹图与检测图构建 3.2.2 图卷积特征提取 3.2.3 多层次图特征融合机制 3.3.4 多特征融合与可微匹配优化
   3. 轨迹管理策略
   4. 实验结果与讨论
   5. 本章小结
4. 跨域自适应多目标检测与跟踪算法研究
   1. 跨域与恶劣环境问题分析
   2. 基于可微图像处理器的跨域自适应增强模块 
   3. 与目标检测和多目标跟踪的协同框架
   4. 实验结果与讨论
   5. 本章小结
5. 总结与展望： 5.1 本文工作总结 5.2 未来工作展望

---

## 1. 绪论

## 2. 基础理论

## 3. 基于图神经网络的多目标跟踪算法研究

### 3.4 实验结果与讨论

#### 3.4.1 实验设置

几个重要的点是 数据集的划分，对比实验用的数据集 是 MOT16 和 MOT17 ；但是消融实验中 使用到的数据集 都是MOT17 。其次，因为MOT Challenge 这个网站的账号一直申请不下来，所以只能自己手动划分数据集，统一的 我们将 每个视频的最后一百帧的数据 划分成测试集，其他都是 训练集。而且都是遵循 public detection 的协议，即都是使用他们给的官方检测数据

还有就是 具体用到的评价指标 （这里 第二章的基础知识中 介绍了 多目标跟踪的评价体系，这里可以 就直接点名就好，不用再赘述） —— HOTA  DetA  AssA  IDF1  IDR  IDP  MOTA  MOTP 这些用到了

还有就是 一些 训练条件： 可以参考 我论文初稿中写的东西，如下：

DGCTracker的代码实现基于Pytorch[?]和Pytorch-Geometric框架[?]，并在NVIDIA RTX 4090 GPU上进行训练。网络在批量大小为16的情况下训练了120个轮次，采用Adam优化器进行参数优化。初始学习率设置为0.02，权重衰减为10^-4^，并使用指数衰减策略调整学习率。在损失函数中，超参数$\alpha$和$\gamma$分别设置为0.25和2。在REID模块中，我们与SUSHI相同，采用了预训练的 ResNet50-IBN ，并仅在其末尾添加几个线性层用于降维。ResNet50-IBN权重在训练过程中保持冻结状态，仅训练降维头的参数。在图构建中，我们选用k=2来进行KNN构图。对于图网络模块，我们设置了3层静态图卷积和2层动态图卷积。

focal loss 中的 alpha = 0.25 gamma = 2 

其中可能有些信息 和 之前重复了。



#### 3.4.2 与先进方法的对比

这里 可以 定量对比 和 定性对比 （先定量在定性）



|   MOT16    | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
| :--------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| GCNNMatch  | 17.89 | 24.50 | 15.40 | 18.10 | 11.10 | 34.78 | 21.53 | 77.10 |
|    GSM     | 19.42 | 24.02 | 15.75 | 19.10 | 12.90 | 36.78 | 22.67 | 77.99 |
|  oc-sort   | 37.65 | 27.77 | 51.50 | 45.51 | 34.47 | 66.95 | 24.93 | 76.90 |
|  Bot-Sort  | 37.68 | 25.81 | 55.32 | 43.78 | 29.73 | 82.96 | 29.58 | 78.86 |
| imprass-oc | 37.76 | 28.52 | 50.61 | 43.11 | 32.59 | 63.69 | 25.20 | 77.32 |
| DGCTracker | 39.54 | 28.71 | 54.91 | 44.91 | 32.64 | 71.97 | 29.66 | 78.33 |



|   MOT17    |   HOTA    |   DetA    |   AssA    |   IDF1    |    IDR    |    IDP    |   MOTA    |   MOTP    |
| :--------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: | :-------: |
| GCNNMatch  |   56.65   |   52.78   |   60.92   |   66.35   |   55.25   |   83.01   |   61.52   |   83.35   |
|    GSM     |   58.25   |   54.89   |   61.97   |   69.01   |   58.94   |   83.22   |   63.94   |   82.82   |
|  oc-sort   |   59.10   |   52.53   |   66.58   |   72.38   |   59.17   | **93.20** |   61.95   |   84.07   |
|  Bot-Sort  |   60.12   |   56.48   |   64.23   |   68.81   |   57.57   |   85.51   |   64.34   |   85.48   |
| imprass-oc |   61.23   | **57.47** |   65.34   |   72.59   | **62.28** |   87.01   | **67.09** |   83.64   |
| DGCTracker | **61.65** |   56.42   | **67.56** | **72.64** |   61.25   |   89.25   |   65.59   | **84.67** |



以上是 定量实验的两个表，希望整合到同一张表里面去。然后说下一段 类似于 DGCTracker 在 MOT16 MOT17中哪些指标比较高的话



然后是定量对比 和初稿中的记录一样 这里更新了下 变成了三幅图（同样需要 给每幅图取一个名字）

第一幅图： 是 MOT17-05的 是 移动视角下的 人员交叉 发生ID切换的情况（第一行是 Imprass-OC的跟踪结果，我放了四帧的跟踪结果—— frame 78 frame 80 frame 82 frame 84;第二行是DGCTracker 也是 这四帧的内容。）

我描述下这个画面，你需要根据我的描述，以及你对DGCTracker的理解和之前第三章的文字来说出 这个场景体现出DGCTracker优越在什么场景下有什么能力优越。—— 为此 我 这里贴出 DGCTracker 提出旨在解决的问题是 在目标密集、遮挡频繁、外观变化大的场景下，传统关联方法难以保持身份一致性。

那么现在具体开始第一副图的描述：

在第78帧到第84帧出现了人员交叉的现象。具体说，在第78帧时，Imprass-OC跟踪器将穿着白衬衫的男人ID分配为134，此时，有个穿着短袖的女生就在此时被这个男人遮挡了。等到第80帧，这个女生重新出现的时候，但是Imprass-OC跟踪器错误的将属于白衬衫男人的ID分配给这个穿短袖的女生，而将白衬衫男人的ID重新分配成 141。于此不同的时， DGCTracker 凭借什么 东西 ，自始自终能够在这个交叉过程中，保持好白衬衫男人的ID，并且给 这个短袖女生重新分配ID。这体现出 DGCTracker什么能力呢？



现在是第二幅图的描述：

第二幅图： MOT17-02的远距离小目标的跟踪（第一行依旧是Imprass-OC的跟踪结果，我也放了四帧结果——frame 71 frame 73 frame 82 frame 84

我描述下这个过程，依旧你需要根据我的描述来完成之前我要求的东西

那么开始第二幅图的描述：

在第71帧和第73帧中，Imprass–OC将一个全身穿着黑色衣服裤子的男人分配ID为5，但是 第82帧的时候 ，突然 这个轨迹ID消失了，同时检测器还是检测到这个男人的，然后在第84帧时，跟踪器又重新把这个男人ID分配成34.而这一过程中，DGCTracker 自始自终 都保持这个男人的ID为5.这体现出DGCTracker 的什么能力比较优越呢？

最后是第三幅图的描述

场景时MOT17-04 第一行时 gsm (这是一个图跟踪方法了)的 frame 22 frame 24 frame 26 frame 28 ；第二行时 DGCTracker 同样四帧的跟踪结果

以下的文字描述 是 论文初稿中一致的（因为是描述同一个 ID变换的过程，只不过frame不一样，这里多放了几帧）

其中展示了在密度场景下，充分提取局部空间关系对多目标跟踪的重要性。具体来说，在第25帧和第28帧，出现了两个外观和位置特征相似的目标。在25帧时，检测器仅检测到穿白色上衣的男性，并将其分配为ID#19。然而，在第28帧，另一位穿白色上衣的女性出现，导致目标之间的混淆。在这种情况下，简单提取局部关系的图方法GSM会发生身份漂移，将ID#19错误地分配给新出现地女性，而原本的白衣男性则被误识别为ID#6。相比之下，DGCTracker 通过层次化提取目标间的特征关系，增强了特征的区分性。面对新出现的相似目标时，DGCTracker  能够为其分配一个新的ID，并且能够保持白衣男性的原本身份信息，从而有效避免了身份漂移问题。



#### 3.4.3 消融实验

消融实验分成三部分 图结构探索 + 图神经网络结构探索 + 数据增强手段

要求每个实验 都需要分析下数据，然后再分析下 为什么 要这样子的选择

图结构探索 

- 有向图 // 无向图  （这里有个图 会展示 有向图 和 无向图的区别 —— 图的标题）

这部分的实验结果如下

| Conditions | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
| :--------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|   无向图   | 58.18 | 56.54 | 62.47 | 67.48 | 56.98 | 82.71 | 64.9  | 84.62 |
|   有向图   | 61.65 | 56.42 | 67.56 | 72.64 | 61.25 | 89.25 | 65.59 | 84.67 |

- 有无自环 （ 这里会有个图 会展示 自环图 和 无自环图的区别，前提是 有向图。而且 会有这样子的特殊情况，如果当前帧仅有一个节点的时候，就默认构造自环图，否则图不成立了）

  | Conditions | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
  | :--------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
  | 有向自环图 | 61.36 | 56.40 | 67.17 | 71.08 | 59.94 | 87.29 | 65.67 | 84.69 |
  | 有向无环图 | 61.65 | 56.42 | 67.56 | 72.64 | 61.25 | 89.25 | 65.59 | 84.67 |

- 构图方式 （ 动态图的构图方式，正文中写的是 特征的余弦距离进行构图，如果使用特征的欧式距离构图会怎么样）

  |     Conditions     | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
  | :----------------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
  | 动态图基于欧式距离 | 59.81 | 56.32 | 65.09 | 70.96 | 59.86 | 87.13 | 64.86 | 84.69 |
  | 动态图基于余弦距离 | 61.65 | 56.42 | 67.56 | 72.64 | 61.25 | 89.25 | 65.59 | 84.67 |

- K的消融实验（这里也有个图 用于展示 K 从 2 3 4 5 6 7 8 9 10 13 14 999——此时变成了全连接图 不同K值的构图结果）

  | Different K | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
  | :---------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
  |     k=2     | 61.65 | 56.42 | 67.56 | 72.64 | 61.25 | 89.25 | 65.59 | 84.67 |
  |      4      | 61.5  | 56.4  | 67.37 | 72.76 | 61.33 | 89.44 | 65.61 | 84.61 |
  |      6      | 61.53 | 56.17 | 67.51 | 72.62 | 61.22 | 89.25 | 65.44 | 84.60 |
  |      8      | 59.91 | 56.14 | 64.76 | 70.3  | 59.3  | 86.36 | 65.17 | 84.7  |
  |     16      | 60.47 | 56.38 | 65.55 | 70.82 | 59.73 | 86.99 | 64.99 | 84.7  |
  |     64      | 60.76 | 56.03 | 66.29 | 71.05 | 59.92 | 87.28 | 64.94 | 84.69 |
  |  全连接图   | 59.94 | 56.23 | 64.76 | 70.24 | 59.24 | 86.28 | 64.96 | 84.66 |

图神经网络的探索

- 静态图 正文中提到过 有来自上一层的残差连接，所以 消融实验中 把这个去掉 看看什么情况

$$
\begin{equation}
    ^{s}h_i^{\beta} = {^{s}g^\beta}\left( ^{s}f_1^\beta\left( ^{s}h_i^{\beta-1} \right) + \max_{j \in \mathcal{N}(i)} {^{s}f_2}^\beta\left( ^{s}z_{ji} ~, \left( ^{s}h_j^{\beta-1} - {^{s}h_i^{\beta-1}} \right) \right) \right)
    \label{equ:sta_gcn}
\end{equation}
$$

去掉静态图的残差连接公式为：但还是保留 动态图卷积的方式（下面我这个公式 是把 去掉残差的静态图卷积公式 和 原本的动态图卷积写到一起了）
$$
\begin{equation}
\begin{cases}
    ^{s}h_i^{\beta} = {^{s}g^\beta}\left(  \max_{j \in \mathcal{N}(i)} {^{s}f_2}^\beta\left( ^{s}z_{ji} ~, \left( ^{s}h_j^{\beta-1} - {^{s}h_i^{\beta-1}} \right) \right) \right) \\
    ^{d}h_i^{\beta} = \max_{j \in \mathcal{N}^{\beta}(i)} {^{d}f^\beta}\left( \left[^{d}h_{i}^{\beta -1} ~\cdot~\left( ^{d}h_j^{\beta-1} - {^{d}h_i^{\beta-1}} \right) \right] \right)
\end{cases}
\end{equation}
$$

| Conditions | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
| :--------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 无残差连接 | 59.53 | 56.35 | 63.83 | 69.3  | 58.49 | 85.03 | 65.23 | 84.63 |
|  残差连接  | 61.65 | 56.42 | 67.56 | 72.64 | 61.25 | 89.25 | 65.59 | 84.67 |

- 修改静态图卷积和动态图卷积的 聚合方式，从max 变成 mean

$$
\begin{equation}
\begin{cases}
    ^{s}h_i^{\beta} = {^{s}g^\beta}\left(  \frac{1}{N}\sum_{j \in \mathcal{N}(i)} {^{s}f_2}^\beta\left( ^{s}z_{ji} ~, \left( ^{s}h_j^{\beta-1} - {^{s}h_i^{\beta-1}} \right) \right) \right) \\
    ^{d}h_i^{\beta} = \frac{1}{N}\sum_{j \in \mathcal{N}^{\beta}(i)} {^{d}f^\beta}\left( \left[^{d}h_{i}^{\beta -1} ~\cdot~\left( ^{d}h_j^{\beta-1} - {^{d}h_i^{\beta-1}} \right) \right] \right)
\end{cases}
\end{equation}
$$

| Conditions | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
| :--------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|    mean    | 58.98 | 55.99 | 63.14 | 69.03 | 58.27 | 84.68 | 65.04 | 84.66 |
|    max     | 61.65 | 56.42 | 67.56 | 72.64 | 61.25 | 89.25 | 65.59 | 84.67 |

- 归一化方式 batchnorm 和 graphnorm 的指标差异

| Conditions | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
| :--------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|    mean    | 61.48 | 56.35 | 67.32 | 71.7  | 60.49 | 88.02 | 64.99 | 84.59 |
|    max     | 61.65 | 56.42 | 67.56 | 72.64 | 61.25 | 89.25 | 65.59 | 84.67 |

- 静态图卷积和动态图卷积的层数配置

我这里直接贴出论文初稿中的数据（s代表 static GCN ,d 代表dynamic GCN）

| MOT17-SDP | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
| :-------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|   1s+1d   | 57.55 | 55.54 | 59.88 | 66.73 | 56.23 | 82.04 | 64.14 | 84.24 |
|    2s     | 59.01 | 54.97 | 63.58 | 69.23 | 58.69 | 84.39 | 62.88 | 84.47 |
|   2s+1d   | 60.43 | 56.08 | 65.33 | 71.45 | 60.21 | 87.85 | 65.35 | 84.60 |
|    3s     | 59.67 | 55.79 | 64.01 | 70.17 | 59.13 | 86.29 | 65.04 | 84.52 |
|   3s+1d   | 60.80 | 56.27 | 65.88 | 71.48 | 60.29 | 87.76 | 65.30 | 84.61 |
|   3s+2d   | 61.65 | 56.42 | 67.56 | 72.64 | 61.25 | 89.25 | 65.59 | 84.67 |

- 还有个 最后 亲和矩阵构造的时候，不用用到三种信息嘛？ 图卷积输出的节点嵌入 + 表观特征 + HIOU

| MOT17-SDP | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
| :-------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|   Node    | 48.65 | 51.56 | 46.26 | 54.01 | 45.27 | 66.95 | 56.50 | 82.98 |
| Node+App  | 53.78 | 54.01 | 53.88 | 61.41 | 51.69 | 75.64 | 61.76 | 84.02 |
| Node+HIoU | 60.34 | 56.15 | 65.05 | 70.99 | 59.87 | 87.18 | 65.28 | 84.54 |
|  Triple   | 61.65 | 56.42 | 67.56 | 72.64 | 61.25 | 89.25 | 65.59 | 84.67 |

数据增强手段：

- 总共使用了三种数据增强手段（正文中特意提及了）
- 所以这里的实验就是 是否启用他们的区别



| MOT17-SDP  | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
| :--------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 无数据增强 | 59.67 | 55.72 | 64.11 | 69.60 | 58.85 | 85.16 | 64.58 | 84.54 |
|  数据增强  | 61.65 | 56.42 | 67.56 | 72.64 | 61.25 | 89.25 | 65.59 | 84.67 |







## 4. 跨域自适应多目标检测与跟踪算法研究



|     method      | VOC 原本测试集map | VOC 雾气测试数据集 |   RTTS    |
| :-------------: | :---------------: | :----------------: | :-------: |
|     YOLOv3      |       64.13       |       63.40        |   30.80   |
|     DA-YOLO     |       56.51       |       55.11        |   29.93   |
|     IA-YOLO     |       73.23       |       72.03        |   37.08   |
|    GDIP-YOLO    |       73.70       |       71.92        |   42.42   |
|    ERUP-YOLO    |       77.89       |       74.09        |   49.81   |
| **CDIE-YOLOv3** |     **82.47**     |     **81.80**      | **56.76** |
| ~~CDIE-YOLOv8~~ |                   |                    |           |









|     method      | VOC 原本测试集map | VOC 弱光测试数据集 |  Exdark   |
| :-------------: | :---------------: | :----------------: | :-------: |
|     YOLOv3      |       65.33       |       52.28        |   37.03   |
|     DA-YOLO     |       41.68       |       21.53        |   18.15   |
|     IA-YOLO     |       70.02       |       59.40        |   40.37   |
|    GDIP-YOLO    |       63.23       |       57.85        |   42.56   |
|    ERUP-YOLO    |       68.62       |       59.81        |   48.43   |
| **CDIE-YOLOv3** |     **84.23**     |     **81.29**      | **57.32** |
| ~~CDIE-YOLOv8~~ |                   |                    |           |



| 层数 | VOC 弱光测试数据集 | Exdark |
| :--: | :----------------: | :----: |
|  1   |       80.88        | 56.67  |
|  2   |       81.07        | 56.48  |
|  3   |       81.17        | 57.15  |
|  4   |       80.90        | 57.22  |
|  5   |       81.29        | 57.32  |
|  6   |       81.08        | 57.41  |



| 权重比例(bezier:kernel) | VOC 弱光测试数据集 | Exdark |
| :---------------------: | :----------------: | :----: |
|           5:5           |       69.69        | 55.63  |
|           4:6           |       66.61        | 54.17  |
|           6:4           |       70.77        | 55.26  |
|           2:8           |       67.90        | 55.00  |
|           8:2           |       71.64        | 56.04  |
|          0:10           |       65.06        | 49.47  |
|          10:0           |       72.16        | 56.04  |
|          gate           |       81.29        | 57.32  |



| vision encoder | VOC 弱光测试数据集 | Exdark |
| :------------: | :----------------: | :----: |
|       fc       |       70.74        | 50.41  |
|      ours      |       81.29        | 57.32  |





|    yolov3    | HOTA  | DetA  | AssA  | IDF1  |  IDR  |  IDP  | MOTA  | MOTP  |
| :----------: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
|    MOT17     | 38.87 | 27.01 | 57.11 | 44.34 | 30.66 | 80.07 | 31.23 | 76.21 |
|  MOT17_dark  | 33.25 | 22.30 | 50.48 | 35.66 | 23.36 | 75.31 | 25.62 | 76.61 |
| MOT17_dedark | 38.08 | 26.42 | 56.18 | 43.05 | 29.53 | 79.42 | 31.04 | 76.11 |
|  MOT17_fog   | 27.25 | 17.56 | 43.11 | 28.11 | 17.62 | 69.54 | 19.03 | 75.56 |
| MOT17_defog  | 34.36 | 23.39 | 51.37 | 37.79 | 25.17 | 75.87 | 26.48 | 75.72 |







|             |  ERUP   | YOLOv3 | DGCTracker |
| :---------: | :-----: | :----: | :--------: |
|   参数量    |  9.85M  | 61.63M |   27.28M   |
| 480p video  | 263 FPS | 64FPS  |   68 FPS   |
| 1080p video |    2    | 55FPS  |   30 FPS   |
