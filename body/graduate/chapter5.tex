\chapter{总结与展望}
\section{本文工作总结}
本文针对多目标跟踪系统在真实复杂场景下面临的轨迹关联模糊与跨域感知退化两大核心挑战，
以提升系统整体鲁棒性与环境适应性为目标，
从后端关联算法与前端视觉增强两个层面开展了系统性研究。主要工作与贡献可概括为以下四个方面：

\textbf{1. 明确了复杂动态场景下多目标跟踪的关键瓶颈，并系统梳理了相关技术的发展脉络}。
本文在绪论与国内外研究现状分析中明确指出，现有算法在应对目标密集遮挡、外观相似以及光照剧变、恶劣天气等跨域条件时，
存在关联模型判别力不足与前端感知质量严重退化的问题。
通过对基于检测的跟踪范式、图神经网络在关联建模中的应用以及跨域自适应方法（特征对齐、图像翻译、前端增强）的深入综述，
为后续针对性创新工作奠定了理论基础并指明了突破口。

\textbf{2. 提出了一种基于双图协同关联的在线多目标跟踪算法（DGCTracker），有效提升了复杂场景下的身份一致性保持能力}。
针对传统图跟踪方法构图冗余、计算复杂度高的问题，第三章创新性地将轨迹关联重新建模为一般图匹配问题，摒弃了跨帧稠密构图策略，转而采用帧内独立构图。
通过引入静态图卷积与动态图卷积的双路协同架构，模型能够同时捕捉目标间稳定的空间几何结构与动态的语义判别关系。
采用KNN稀疏构图与有向边设计，显著降低了高密度场景下的计算开销。
在匹配阶段，融合图上下文、外观纹理与几何特征构建多模态亲和矩阵，并利用可微Sinkhorn算法进行端到端优化，
最终通过匈牙利算法完成精准关联。
在MOT16/17基准上的实验表明，该方法在HOTA、AssA、IDF1等关联核心指标上优于多种先进方法，
尤其在目标交叉、远距离小目标及密集相似人群场景中展现出更强的身份保持鲁棒性。

\textbf{3. 设计了一种面向跨域场景的双渐进滤波前端自适应增强与检测框架（DPFE-YOLO），从源头缓解了视觉退化对感知系统的冲击}。
针对恶劣天气导致检测性能级联退化的问题，第四章提出了一种轻量化、可学习的图像增强器。该增强器由全卷积视觉编码器与级联双流滤波块（DFB）构成。
每个DFB并行执行贝塞尔像素级滤波（BPW）进行全局色调映射与基于核的局部滤波（KBL）进行细节恢复，并通过门控网络自适应融合。
其采用语义驱动的渐进式架构，利用编码器不同层级的特征逐步引导从全局校正到局部修复的增强过程。
为了解决增强器与检测器（YOLOv3）端到端协同训练的不稳定性，提出了“预热-联合”两阶段训练策略及融合重建、结构、色彩与感知损失的混合损失函数。
在PASCAL VOC、ExDark、RTTS等跨域检测数据集上的实验证明，该方法在合成与真实雾天、弱光场景下的检测性能显著优于已有自适应方法，且增强结果在视觉自然度与细节保留上更具优势。

\textbf{4. 构建了一个模块化、轻量化的跨域自适应多目标检测与跟踪完整系统，并验证了其工程实用性}。
 本文将训练好的DPFE增强模块与YOLOv3检测器、第三章的DGCTracker跟踪器进行集成，形成了“增强-检测-跟踪”的串行推理流水线。该系统能够对输入的退化视频流进行实时增强，为下游模块提供高质量的视觉输入。
 实验表明，在合成退化的MOT17数据集上，该集成系统能有效恢复因视觉退化而损失的跟踪性能（HOTA、MOTA等指标大幅回升），显著抑制了轨迹碎片化与身份混淆。
 进一步的系统效率分析显示，所提出的DPFE增强模块参数量仅为9.85M，在1080P分辨率下推理速度超过200 FPS，
 其轻量化与高实时性特性，以及模块化解耦的设计，为在边缘计算设备上的实际部署提供了良好基础。

\section{未来工作展望}
本文围绕复杂环境下多目标跟踪的鲁棒关联与跨域自适应感知问题展开了深入研究，并取得了阶段性成果。
然而，当前方法仍然存在一些局限，未来的研究将重点聚焦于以下两个维度的改进与探索：

\textbf{1. 图神经网络跟踪算法的深度优化}

本文提出的 DGCTracker 虽然利用双图协同机制不仅有效利用了局部和全局信息，还有效解决了短时遮挡问题，但在长时序建模与特征融合策略上仍有改进余地：

\textbf{（1） 增强长时记忆与重识别能力}。
当前的图网络主要基于滑动窗口内的短时帧间关联，当目标发生长时遮挡或暂时离开视场后（例如超过 30 帧），基于位置邻域的稀疏图构建机制可能会因目标丢失而切断连接，导致轨迹中断。
未来的工作可以引入全局特征库（Gallery），用来存储目标的历史外观特征与运动模式。
当目标再次出现时，不仅在当前图结构内进行匹配，还可与历史记忆库进行检索比对，从而显著提升算法的长时跟踪能力。

\textbf{（2） 优化节点表观与边几何特征的自适应平衡}。
在实际跟踪过程中，表观特征（节点嵌入）与运动特征（边属性）的可靠性是动态变化的。
例如在相机急剧抖动时运动特征失效，而在目标模糊时表观特征失效。
当前模型在特征融合时缺乏对两者置信度的显式评估，容易导致某一类特征（尤其是易受干扰的表观特征）主导匹配决策，进而引发 ID 频繁切换。
未来可探索设计一种不确定性感知的注意力机制，根据特征的方差或分布动态学习节点特征与边特征的融合权重，在表观模糊时自动侧重于几何关联，从而提升目标身份的一致性。

\textbf{（3） 探索社会力模型与异构图构建}。
目前的图结构主要基于 KNN 构建几何邻域，尚未深入挖掘人与人之间复杂的社会交互规则（如避让、伴行）。
未来可尝试构建异构图（Heterogeneous Graph），将“行人-行人”交互与“行人-环境”交互区分建模，
引入社会力模型（Social Force Model）作为物理约束，以更精准地预测复杂拥挤场景下的非线性运动轨迹。

\textbf{2. 跨域自适应感知框架的泛化与扩展}

本文第四章提出的 DPFE-YOLO 框架虽然验证了“前端增强服务于后端检测”的有效性，但在处理极端恶劣环境的通用性与精细度上仍需进一步完善：

\textbf{（1） 强化去雾深度与噪声抑制机制}。
实验发现，当前增强模块在极低照度下提亮图像时容易放大传感器噪声，且在浓雾场景下的去雾透射率估计尚不够精准。
后续改进可考虑在增强模块中嵌入专用的去噪分支，利用物理成像模型约束噪声分布；
同时，结合单目深度估计辅助去雾任务，利用深度先验信息来纠正远距离目标的雾气残留问题，以实现更纯净的视觉重构。

\textbf{（2） 构建“全天候”统一增强模型}。
当前框架针对弱光和雾天需要分别训练不同的权重模型，缺乏在未知多变天气下的通用性。
未来的研究可致力于提出一种统一权重的全能复原网络（All-in-One Network）。
可以通过引入“提示学习（Prompt Learning）”或轻量级的天气分类器，
根据输入图像的退化类型（如当前是雨、雾还是黑夜）生成特定的条件编码，
动态调制增强网络的归一化层或卷积核，从而实现单一模型对多种恶劣气象的自适应处理。